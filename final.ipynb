{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psshri/Pan-IIT-Hackathon-2019/blob/master/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sbHgg_vX9pDA",
        "colab_type": "code",
        "outputId": "89be5ab3-770c-4036-c944-b17dafa724aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qIrYi3sjG_uS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e21830cd-c00e-4f0f-e1ff-907ae648f6d5"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zIDpUQ3JHAMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a95939d-a5c0-4c97-e704-4f36b0752677"
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"drive/My Drive/Colab Notebooks/data/training.5k.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cJ67idW7HSqQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPak5UJSHIdE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "084a203f-3ce0-472c-916b-b1fc59824fd0"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import natsort\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn import model_selection\n",
        "from keras.models import load_model\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LXnsd13VHKhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = 'training/training'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aTq4dZUrHNRa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "solution = pd.read_csv('training/solution.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAjiepGTHPMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4312429a-c94f-4a3d-8798-dfac98ad7843"
      },
      "cell_type": "code",
      "source": [
        "IMG_SIZE=240\n",
        "train_data_240=[]\n",
        "labels_240=[]\n",
        "for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "    path = os.path.join(TRAIN_DIR,img)\n",
        "    img_data = cv2.imread(path)\n",
        "    img_data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n",
        "    train_data_240.append([np.array(img_data)])\n",
        "    number = int(img[:-4])\n",
        "    categ_num = int(solution[solution.id==number].category)\n",
        "    labels_240.append(categ_num)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:17<00:00, 286.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FcGmJbedHRQy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lb=LabelBinarizer()\n",
        "labels_240=lb.fit_transform(labels_240)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cdtBmUWbHhjJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=model_selection.train_test_split(train_data_240,labels_240,test_size=0.25,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3mBkJk6sHiZy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aug=ImageDataGenerator(rotation_range=25,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.2,horizontal_flip=True,fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "834WecqFHmw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding=\"same\",activation=\"linear\",input_shape=(240,240,3)))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(32,(3,3),padding=\"same\",activation=\"linear\"))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(Conv2D(64,(3,3),padding=\"same\",activation=\"linear\"))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),padding=\"same\",activation=\"linear\"))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128,(3,3),padding=\"same\",activation=\"relu\"))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024,activation=\"linear\"))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6,activation=\"softmax\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qkv4inb7Hvir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oCfUamoGHxXj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.array([i[0] for i in x_train]).reshape(-1,240,240,3)\n",
        "x_test = np.array([i[0] for i in x_test]).reshape(-1,240,240,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8alCedZNHzHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uajPbyWPH0wP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5137
        },
        "outputId": "216f0a34-126c-4adf-f04c-73d492698182"
      },
      "cell_type": "code",
      "source": [
        "train=model.fit_generator(aug.flow(x_train,y_train,batch_size=64),validation_data=(x_test,y_test),steps_per_epoch=len(x_train)/64,epochs=150,verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "59/58 [==============================] - 58s 991ms/step - loss: 2.9007 - acc: 0.1954 - val_loss: 2.0512 - val_acc: 0.2376\n",
            "Epoch 2/150\n",
            "59/58 [==============================] - 52s 874ms/step - loss: 2.1890 - acc: 0.2299 - val_loss: 1.9627 - val_acc: 0.2504\n",
            "Epoch 3/150\n",
            "59/58 [==============================] - 51s 860ms/step - loss: 2.0862 - acc: 0.2364 - val_loss: 1.7919 - val_acc: 0.2656\n",
            "Epoch 4/150\n",
            "59/58 [==============================] - 51s 862ms/step - loss: 2.0041 - acc: 0.2576 - val_loss: 2.2376 - val_acc: 0.2784\n",
            "Epoch 5/150\n",
            "59/58 [==============================] - 52s 878ms/step - loss: 1.8468 - acc: 0.2584 - val_loss: 3.6280 - val_acc: 0.2504\n",
            "Epoch 6/150\n",
            "59/58 [==============================] - 51s 869ms/step - loss: 1.8495 - acc: 0.2652 - val_loss: 1.9607 - val_acc: 0.2880\n",
            "Epoch 7/150\n",
            "59/58 [==============================] - 53s 892ms/step - loss: 1.7873 - acc: 0.2752 - val_loss: 1.9540 - val_acc: 0.2664\n",
            "Epoch 8/150\n",
            "59/58 [==============================] - 53s 896ms/step - loss: 1.7362 - acc: 0.2775 - val_loss: 2.5059 - val_acc: 0.2656\n",
            "Epoch 9/150\n",
            "59/58 [==============================] - 52s 887ms/step - loss: 1.6930 - acc: 0.2865 - val_loss: 1.8613 - val_acc: 0.2136\n",
            "Epoch 10/150\n",
            "59/58 [==============================] - 53s 892ms/step - loss: 1.5982 - acc: 0.2980 - val_loss: 1.7798 - val_acc: 0.2312\n",
            "Epoch 11/150\n",
            "59/58 [==============================] - 52s 886ms/step - loss: 1.5955 - acc: 0.3015 - val_loss: 1.9246 - val_acc: 0.2208\n",
            "Epoch 12/150\n",
            "59/58 [==============================] - 53s 893ms/step - loss: 1.6046 - acc: 0.3117 - val_loss: 3.3610 - val_acc: 0.2304\n",
            "Epoch 13/150\n",
            "59/58 [==============================] - 53s 892ms/step - loss: 1.5505 - acc: 0.2897 - val_loss: 3.9290 - val_acc: 0.1824\n",
            "Epoch 14/150\n",
            "59/58 [==============================] - 53s 903ms/step - loss: 1.4958 - acc: 0.3176 - val_loss: 2.0018 - val_acc: 0.2648\n",
            "Epoch 15/150\n",
            "59/58 [==============================] - 53s 899ms/step - loss: 1.4733 - acc: 0.3176 - val_loss: 2.4436 - val_acc: 0.1984\n",
            "Epoch 16/150\n",
            "59/58 [==============================] - 53s 902ms/step - loss: 1.4258 - acc: 0.3164 - val_loss: 1.8388 - val_acc: 0.2536\n",
            "Epoch 17/150\n",
            "59/58 [==============================] - 53s 903ms/step - loss: 1.3813 - acc: 0.3349 - val_loss: 1.6316 - val_acc: 0.3088\n",
            "Epoch 18/150\n",
            "59/58 [==============================] - 53s 905ms/step - loss: 1.4038 - acc: 0.3312 - val_loss: 5.3965 - val_acc: 0.1736\n",
            "Epoch 19/150\n",
            "59/58 [==============================] - 53s 905ms/step - loss: 1.3688 - acc: 0.3276 - val_loss: 1.8853 - val_acc: 0.2872\n",
            "Epoch 20/150\n",
            "59/58 [==============================] - 54s 907ms/step - loss: 1.3254 - acc: 0.3503 - val_loss: 5.4680 - val_acc: 0.1760\n",
            "Epoch 21/150\n",
            "59/58 [==============================] - 53s 903ms/step - loss: 1.3369 - acc: 0.3722 - val_loss: 2.3358 - val_acc: 0.2496\n",
            "Epoch 22/150\n",
            "59/58 [==============================] - 53s 906ms/step - loss: 1.3085 - acc: 0.3729 - val_loss: 2.1606 - val_acc: 0.2856\n",
            "Epoch 23/150\n",
            "59/58 [==============================] - 53s 906ms/step - loss: 1.2722 - acc: 0.3939 - val_loss: 1.7462 - val_acc: 0.3616\n",
            "Epoch 24/150\n",
            "59/58 [==============================] - 54s 911ms/step - loss: 1.2345 - acc: 0.4114 - val_loss: 3.0389 - val_acc: 0.2784\n",
            "Epoch 25/150\n",
            "59/58 [==============================] - 54s 907ms/step - loss: 1.2598 - acc: 0.4301 - val_loss: 8.2596 - val_acc: 0.1696\n",
            "Epoch 26/150\n",
            "59/58 [==============================] - 54s 915ms/step - loss: 1.1470 - acc: 0.4616 - val_loss: 3.4316 - val_acc: 0.3160\n",
            "Epoch 27/150\n",
            "59/58 [==============================] - 54s 908ms/step - loss: 1.1105 - acc: 0.4757 - val_loss: 3.0168 - val_acc: 0.2624\n",
            "Epoch 28/150\n",
            "59/58 [==============================] - 54s 913ms/step - loss: 0.9748 - acc: 0.5428 - val_loss: 2.5741 - val_acc: 0.3272\n",
            "Epoch 29/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.9124 - acc: 0.5803 - val_loss: 1.3022 - val_acc: 0.4464\n",
            "Epoch 30/150\n",
            "59/58 [==============================] - 54s 908ms/step - loss: 0.7968 - acc: 0.6440 - val_loss: 2.0751 - val_acc: 0.3376\n",
            "Epoch 31/150\n",
            "59/58 [==============================] - 53s 904ms/step - loss: 0.6938 - acc: 0.7032 - val_loss: 0.8857 - val_acc: 0.6448\n",
            "Epoch 32/150\n",
            "59/58 [==============================] - 53s 906ms/step - loss: 0.5764 - acc: 0.7645 - val_loss: 0.5605 - val_acc: 0.7952\n",
            "Epoch 33/150\n",
            "59/58 [==============================] - 53s 906ms/step - loss: 0.5768 - acc: 0.7626 - val_loss: 0.3847 - val_acc: 0.8576\n",
            "Epoch 34/150\n",
            "59/58 [==============================] - 53s 902ms/step - loss: 0.4956 - acc: 0.8057 - val_loss: 0.3632 - val_acc: 0.8728\n",
            "Epoch 35/150\n",
            "59/58 [==============================] - 53s 891ms/step - loss: 0.4365 - acc: 0.8269 - val_loss: 0.9502 - val_acc: 0.7376\n",
            "Epoch 36/150\n",
            "59/58 [==============================] - 54s 914ms/step - loss: 0.4184 - acc: 0.8365 - val_loss: 0.1883 - val_acc: 0.9352\n",
            "Epoch 37/150\n",
            "59/58 [==============================] - 54s 911ms/step - loss: 0.3907 - acc: 0.8451 - val_loss: 0.2606 - val_acc: 0.9040\n",
            "Epoch 38/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.3797 - acc: 0.8548 - val_loss: 5.2396 - val_acc: 0.4840\n",
            "Epoch 39/150\n",
            "59/58 [==============================] - 53s 906ms/step - loss: 0.3346 - acc: 0.8710 - val_loss: 0.5948 - val_acc: 0.8192\n",
            "Epoch 40/150\n",
            "59/58 [==============================] - 53s 907ms/step - loss: 0.3194 - acc: 0.8767 - val_loss: 0.3894 - val_acc: 0.8752\n",
            "Epoch 41/150\n",
            "59/58 [==============================] - 53s 903ms/step - loss: 0.3121 - acc: 0.8836 - val_loss: 0.3084 - val_acc: 0.9064\n",
            "Epoch 42/150\n",
            "59/58 [==============================] - 53s 903ms/step - loss: 0.2934 - acc: 0.8953 - val_loss: 0.4091 - val_acc: 0.8688\n",
            "Epoch 43/150\n",
            "59/58 [==============================] - 54s 911ms/step - loss: 0.2620 - acc: 0.8999 - val_loss: 0.2989 - val_acc: 0.9096\n",
            "Epoch 44/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.2563 - acc: 0.9053 - val_loss: 0.3859 - val_acc: 0.8824\n",
            "Epoch 45/150\n",
            "59/58 [==============================] - 54s 911ms/step - loss: 0.2638 - acc: 0.9020 - val_loss: 0.2103 - val_acc: 0.9296\n",
            "Epoch 46/150\n",
            "59/58 [==============================] - 54s 912ms/step - loss: 0.2133 - acc: 0.9245 - val_loss: 0.4440 - val_acc: 0.8664\n",
            "Epoch 47/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.2046 - acc: 0.9260 - val_loss: 0.1454 - val_acc: 0.9608\n",
            "Epoch 48/150\n",
            "59/58 [==============================] - 54s 911ms/step - loss: 0.2482 - acc: 0.9108 - val_loss: 0.4285 - val_acc: 0.8648\n",
            "Epoch 49/150\n",
            "59/58 [==============================] - 54s 910ms/step - loss: 0.2366 - acc: 0.9200 - val_loss: 0.8275 - val_acc: 0.7928\n",
            "Epoch 50/150\n",
            "59/58 [==============================] - 54s 907ms/step - loss: 0.2041 - acc: 0.9293 - val_loss: 0.3555 - val_acc: 0.8904\n",
            "Epoch 51/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.1889 - acc: 0.9375 - val_loss: 0.7710 - val_acc: 0.8064\n",
            "Epoch 52/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.2240 - acc: 0.9210 - val_loss: 0.3722 - val_acc: 0.8968\n",
            "Epoch 53/150\n",
            "59/58 [==============================] - 53s 907ms/step - loss: 0.2058 - acc: 0.9235 - val_loss: 0.7730 - val_acc: 0.7968\n",
            "Epoch 54/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.2127 - acc: 0.9246 - val_loss: 0.2482 - val_acc: 0.9248\n",
            "Epoch 55/150\n",
            "59/58 [==============================] - 54s 913ms/step - loss: 0.1877 - acc: 0.9342 - val_loss: 0.2307 - val_acc: 0.9280\n",
            "Epoch 56/150\n",
            "59/58 [==============================] - 54s 912ms/step - loss: 0.1876 - acc: 0.9325 - val_loss: 0.2352 - val_acc: 0.9272\n",
            "Epoch 57/150\n",
            "59/58 [==============================] - 54s 914ms/step - loss: 0.1743 - acc: 0.9339 - val_loss: 0.2364 - val_acc: 0.9296\n",
            "Epoch 58/150\n",
            "59/58 [==============================] - 54s 911ms/step - loss: 0.1832 - acc: 0.9360 - val_loss: 0.1379 - val_acc: 0.9560\n",
            "Epoch 59/150\n",
            "59/58 [==============================] - 54s 914ms/step - loss: 0.1606 - acc: 0.9431 - val_loss: 0.1277 - val_acc: 0.9632\n",
            "Epoch 60/150\n",
            "59/58 [==============================] - 54s 914ms/step - loss: 0.1505 - acc: 0.9481 - val_loss: 0.3496 - val_acc: 0.8968\n",
            "Epoch 61/150\n",
            "59/58 [==============================] - 54s 910ms/step - loss: 0.1580 - acc: 0.9463 - val_loss: 0.9656 - val_acc: 0.7616\n",
            "Epoch 62/150\n",
            "59/58 [==============================] - 54s 916ms/step - loss: 0.1667 - acc: 0.9393 - val_loss: 0.1500 - val_acc: 0.9496\n",
            "Epoch 63/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.1609 - acc: 0.9449 - val_loss: 0.1291 - val_acc: 0.9640\n",
            "Epoch 64/150\n",
            "59/58 [==============================] - 54s 907ms/step - loss: 0.1630 - acc: 0.9441 - val_loss: 0.5691 - val_acc: 0.8416\n",
            "Epoch 65/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.1741 - acc: 0.9387 - val_loss: 0.3332 - val_acc: 0.8960\n",
            "Epoch 66/150\n",
            "59/58 [==============================] - 54s 910ms/step - loss: 0.1438 - acc: 0.9480 - val_loss: 0.4329 - val_acc: 0.8584\n",
            "Epoch 67/150\n",
            "59/58 [==============================] - 54s 909ms/step - loss: 0.1429 - acc: 0.9544 - val_loss: 0.1123 - val_acc: 0.9664\n",
            "Epoch 68/150\n",
            "59/58 [==============================] - 53s 903ms/step - loss: 0.1414 - acc: 0.9475 - val_loss: 0.1782 - val_acc: 0.9456\n",
            "Epoch 69/150\n",
            "59/58 [==============================] - 54s 911ms/step - loss: 0.1477 - acc: 0.9462 - val_loss: 0.0635 - val_acc: 0.9808\n",
            "Epoch 70/150\n",
            "59/58 [==============================] - 53s 906ms/step - loss: 0.1568 - acc: 0.9464 - val_loss: 0.2316 - val_acc: 0.9344\n",
            "Epoch 71/150\n",
            "59/58 [==============================] - 52s 888ms/step - loss: 0.1220 - acc: 0.9573 - val_loss: 4.2658 - val_acc: 0.5320\n",
            "Epoch 72/150\n",
            "59/58 [==============================] - 53s 892ms/step - loss: 0.1491 - acc: 0.9476 - val_loss: 0.1388 - val_acc: 0.9624\n",
            "Epoch 73/150\n",
            "59/58 [==============================] - 52s 887ms/step - loss: 0.1423 - acc: 0.9515 - val_loss: 1.1209 - val_acc: 0.7744\n",
            "Epoch 74/150\n",
            "59/58 [==============================] - 52s 876ms/step - loss: 0.1272 - acc: 0.9576 - val_loss: 0.0539 - val_acc: 0.9856\n",
            "Epoch 75/150\n",
            "59/58 [==============================] - 52s 876ms/step - loss: 0.1478 - acc: 0.9525 - val_loss: 0.1283 - val_acc: 0.9608\n",
            "Epoch 76/150\n",
            "59/58 [==============================] - 52s 875ms/step - loss: 0.1269 - acc: 0.9545 - val_loss: 0.1381 - val_acc: 0.9616\n",
            "Epoch 77/150\n",
            "59/58 [==============================] - 52s 873ms/step - loss: 0.1205 - acc: 0.9592 - val_loss: 0.1522 - val_acc: 0.9584\n",
            "Epoch 78/150\n",
            "59/58 [==============================] - 52s 885ms/step - loss: 0.1234 - acc: 0.9564 - val_loss: 0.7550 - val_acc: 0.8032\n",
            "Epoch 79/150\n",
            "59/58 [==============================] - 52s 880ms/step - loss: 0.1000 - acc: 0.9632 - val_loss: 0.0996 - val_acc: 0.9720\n",
            "Epoch 80/150\n",
            "59/58 [==============================] - 51s 869ms/step - loss: 0.1134 - acc: 0.9596 - val_loss: 0.2261 - val_acc: 0.9464\n",
            "Epoch 81/150\n",
            "59/58 [==============================] - 51s 872ms/step - loss: 0.1279 - acc: 0.9578 - val_loss: 0.6739 - val_acc: 0.8712\n",
            "Epoch 82/150\n",
            "59/58 [==============================] - 51s 870ms/step - loss: 0.1305 - acc: 0.9547 - val_loss: 0.1247 - val_acc: 0.9552\n",
            "Epoch 83/150\n",
            "59/58 [==============================] - 52s 873ms/step - loss: 0.1178 - acc: 0.9597 - val_loss: 0.1296 - val_acc: 0.9672\n",
            "Epoch 84/150\n",
            "59/58 [==============================] - 52s 884ms/step - loss: 0.1073 - acc: 0.9664 - val_loss: 0.2441 - val_acc: 0.9280\n",
            "Epoch 85/150\n",
            "59/58 [==============================] - 51s 872ms/step - loss: 0.1346 - acc: 0.9560 - val_loss: 0.1334 - val_acc: 0.9608\n",
            "Epoch 86/150\n",
            "59/58 [==============================] - 50s 853ms/step - loss: 0.1366 - acc: 0.9566 - val_loss: 0.6043 - val_acc: 0.8464\n",
            "Epoch 87/150\n",
            "59/58 [==============================] - 50s 840ms/step - loss: 0.1367 - acc: 0.9566 - val_loss: 0.0938 - val_acc: 0.9752\n",
            "Epoch 88/150\n",
            "59/58 [==============================] - 50s 844ms/step - loss: 0.1062 - acc: 0.9627 - val_loss: 0.1576 - val_acc: 0.9736\n",
            "Epoch 89/150\n",
            "59/58 [==============================] - 49s 826ms/step - loss: 0.0960 - acc: 0.9656 - val_loss: 0.4592 - val_acc: 0.8760\n",
            "Epoch 90/150\n",
            "59/58 [==============================] - 50s 846ms/step - loss: 0.1050 - acc: 0.9666 - val_loss: 0.0624 - val_acc: 0.9832\n",
            "Epoch 91/150\n",
            "59/58 [==============================] - 49s 832ms/step - loss: 0.0979 - acc: 0.9674 - val_loss: 0.1124 - val_acc: 0.9696\n",
            "Epoch 92/150\n",
            "59/58 [==============================] - 48s 817ms/step - loss: 0.1119 - acc: 0.9624 - val_loss: 0.0577 - val_acc: 0.9848\n",
            "Epoch 93/150\n",
            "59/58 [==============================] - 48s 818ms/step - loss: 0.0912 - acc: 0.9692 - val_loss: 0.2092 - val_acc: 0.9416\n",
            "Epoch 94/150\n",
            "59/58 [==============================] - 49s 833ms/step - loss: 0.1130 - acc: 0.9653 - val_loss: 0.1682 - val_acc: 0.9552\n",
            "Epoch 95/150\n",
            "59/58 [==============================] - 49s 826ms/step - loss: 0.0965 - acc: 0.9658 - val_loss: 0.4044 - val_acc: 0.8928\n",
            "Epoch 96/150\n",
            "59/58 [==============================] - 49s 824ms/step - loss: 0.1106 - acc: 0.9627 - val_loss: 0.5476 - val_acc: 0.8416\n",
            "Epoch 97/150\n",
            "59/58 [==============================] - 51s 858ms/step - loss: 0.1104 - acc: 0.9607 - val_loss: 0.9999 - val_acc: 0.7512\n",
            "Epoch 98/150\n",
            "59/58 [==============================] - 48s 818ms/step - loss: 0.1019 - acc: 0.9661 - val_loss: 0.6162 - val_acc: 0.8456\n",
            "Epoch 99/150\n",
            "59/58 [==============================] - 48s 819ms/step - loss: 0.1105 - acc: 0.9606 - val_loss: 0.1270 - val_acc: 0.9624\n",
            "Epoch 100/150\n",
            "59/58 [==============================] - 49s 823ms/step - loss: 0.0829 - acc: 0.9711 - val_loss: 0.1122 - val_acc: 0.9704\n",
            "Epoch 101/150\n",
            "59/58 [==============================] - 48s 816ms/step - loss: 0.1078 - acc: 0.9620 - val_loss: 0.1126 - val_acc: 0.9704\n",
            "Epoch 102/150\n",
            "59/58 [==============================] - 48s 816ms/step - loss: 0.0956 - acc: 0.9672 - val_loss: 0.0609 - val_acc: 0.9776\n",
            "Epoch 103/150\n",
            "59/58 [==============================] - 49s 837ms/step - loss: 0.0972 - acc: 0.9672 - val_loss: 0.1357 - val_acc: 0.9584\n",
            "Epoch 104/150\n",
            "59/58 [==============================] - 51s 857ms/step - loss: 0.0871 - acc: 0.9698 - val_loss: 0.2101 - val_acc: 0.9480\n",
            "Epoch 105/150\n",
            "59/58 [==============================] - 52s 875ms/step - loss: 0.0913 - acc: 0.9695 - val_loss: 0.1363 - val_acc: 0.9576\n",
            "Epoch 106/150\n",
            "59/58 [==============================] - 50s 854ms/step - loss: 0.0996 - acc: 0.9661 - val_loss: 0.5171 - val_acc: 0.8656\n",
            "Epoch 107/150\n",
            "59/58 [==============================] - 50s 849ms/step - loss: 0.0708 - acc: 0.9730 - val_loss: 4.6105 - val_acc: 0.5288\n",
            "Epoch 108/150\n",
            "59/58 [==============================] - 49s 832ms/step - loss: 0.0993 - acc: 0.9682 - val_loss: 0.0895 - val_acc: 0.9816\n",
            "Epoch 109/150\n",
            "59/58 [==============================] - 50s 855ms/step - loss: 0.0878 - acc: 0.9678 - val_loss: 0.0904 - val_acc: 0.9800\n",
            "Epoch 110/150\n",
            "59/58 [==============================] - 50s 841ms/step - loss: 0.0879 - acc: 0.9693 - val_loss: 0.1439 - val_acc: 0.9704\n",
            "Epoch 111/150\n",
            "59/58 [==============================] - 49s 827ms/step - loss: 0.0891 - acc: 0.9715 - val_loss: 0.1218 - val_acc: 0.9632\n",
            "Epoch 112/150\n",
            "59/58 [==============================] - 49s 831ms/step - loss: 0.1077 - acc: 0.9627 - val_loss: 0.0605 - val_acc: 0.9800\n",
            "Epoch 113/150\n",
            "59/58 [==============================] - 51s 858ms/step - loss: 0.1043 - acc: 0.9672 - val_loss: 0.1362 - val_acc: 0.9552\n",
            "Epoch 114/150\n",
            "59/58 [==============================] - 52s 874ms/step - loss: 0.0914 - acc: 0.9693 - val_loss: 0.1427 - val_acc: 0.9632\n",
            "Epoch 115/150\n",
            "59/58 [==============================] - 52s 875ms/step - loss: 0.0713 - acc: 0.9778 - val_loss: 0.1474 - val_acc: 0.9488\n",
            "Epoch 116/150\n",
            "59/58 [==============================] - 52s 882ms/step - loss: 0.0925 - acc: 0.9697 - val_loss: 0.1158 - val_acc: 0.9664\n",
            "Epoch 117/150\n",
            "59/58 [==============================] - 52s 882ms/step - loss: 0.0879 - acc: 0.9700 - val_loss: 0.1520 - val_acc: 0.9624\n",
            "Epoch 118/150\n",
            "59/58 [==============================] - 52s 886ms/step - loss: 0.0889 - acc: 0.9714 - val_loss: 0.8708 - val_acc: 0.8136\n",
            "Epoch 119/150\n",
            "59/58 [==============================] - 52s 886ms/step - loss: 0.0846 - acc: 0.9730 - val_loss: 1.1057 - val_acc: 0.7896\n",
            "Epoch 120/150\n",
            "59/58 [==============================] - 52s 889ms/step - loss: 0.0775 - acc: 0.9755 - val_loss: 0.0469 - val_acc: 0.9848\n",
            "Epoch 121/150\n",
            "59/58 [==============================] - 53s 900ms/step - loss: 0.0946 - acc: 0.9702 - val_loss: 0.1043 - val_acc: 0.9712\n",
            "Epoch 122/150\n",
            "59/58 [==============================] - 53s 900ms/step - loss: 0.1029 - acc: 0.9649 - val_loss: 0.5241 - val_acc: 0.8968\n",
            "Epoch 123/150\n",
            "59/58 [==============================] - 53s 900ms/step - loss: 0.0835 - acc: 0.9706 - val_loss: 0.1304 - val_acc: 0.9640\n",
            "Epoch 124/150\n",
            "59/58 [==============================] - 53s 897ms/step - loss: 0.0830 - acc: 0.9707 - val_loss: 0.2699 - val_acc: 0.9320\n",
            "Epoch 125/150\n",
            "59/58 [==============================] - 53s 901ms/step - loss: 0.0831 - acc: 0.9712 - val_loss: 0.1380 - val_acc: 0.9608\n",
            "Epoch 126/150\n",
            "59/58 [==============================] - 53s 904ms/step - loss: 0.0843 - acc: 0.9727 - val_loss: 0.0660 - val_acc: 0.9744\n",
            "Epoch 127/150\n",
            "59/58 [==============================] - 54s 912ms/step - loss: 0.0780 - acc: 0.9738 - val_loss: 0.0993 - val_acc: 0.9680\n",
            "Epoch 128/150\n",
            "59/58 [==============================] - 53s 902ms/step - loss: 0.0773 - acc: 0.9730 - val_loss: 0.1406 - val_acc: 0.9560\n",
            "Epoch 129/150\n",
            "59/58 [==============================] - 53s 899ms/step - loss: 0.0677 - acc: 0.9760 - val_loss: 0.7249 - val_acc: 0.8368\n",
            "Epoch 130/150\n",
            "59/58 [==============================] - 53s 901ms/step - loss: 0.0866 - acc: 0.9687 - val_loss: 0.1225 - val_acc: 0.9640\n",
            "Epoch 131/150\n",
            "59/58 [==============================] - 53s 899ms/step - loss: 0.0768 - acc: 0.9732 - val_loss: 0.2115 - val_acc: 0.9464\n",
            "Epoch 132/150\n",
            "59/58 [==============================] - 53s 898ms/step - loss: 0.0957 - acc: 0.9705 - val_loss: 0.6323 - val_acc: 0.8624\n",
            "Epoch 133/150\n",
            "59/58 [==============================] - 54s 914ms/step - loss: 0.0971 - acc: 0.9666 - val_loss: 0.1073 - val_acc: 0.9704\n",
            "Epoch 134/150\n",
            "59/58 [==============================] - 53s 898ms/step - loss: 0.0812 - acc: 0.9752 - val_loss: 0.2867 - val_acc: 0.9216\n",
            "Epoch 135/150\n",
            "59/58 [==============================] - 53s 904ms/step - loss: 0.0889 - acc: 0.9724 - val_loss: 0.0763 - val_acc: 0.9856\n",
            "Epoch 136/150\n",
            "59/58 [==============================] - 53s 906ms/step - loss: 0.0716 - acc: 0.9779 - val_loss: 0.1371 - val_acc: 0.9640\n",
            "Epoch 137/150\n",
            "59/58 [==============================] - 54s 908ms/step - loss: 0.0936 - acc: 0.9699 - val_loss: 0.2808 - val_acc: 0.9336\n",
            "Epoch 138/150\n",
            "59/58 [==============================] - 53s 906ms/step - loss: 0.0652 - acc: 0.9778 - val_loss: 0.0546 - val_acc: 0.9816\n",
            "Epoch 139/150\n",
            "59/58 [==============================] - 54s 907ms/step - loss: 0.0722 - acc: 0.9772 - val_loss: 0.2723 - val_acc: 0.9328\n",
            "Epoch 140/150\n",
            "59/58 [==============================] - 53s 897ms/step - loss: 0.0757 - acc: 0.9755 - val_loss: 0.0496 - val_acc: 0.9832\n",
            "Epoch 141/150\n",
            "59/58 [==============================] - 53s 900ms/step - loss: 0.0637 - acc: 0.9820 - val_loss: 0.0985 - val_acc: 0.9760\n",
            "Epoch 142/150\n",
            "59/58 [==============================] - 53s 903ms/step - loss: 0.0749 - acc: 0.9756 - val_loss: 0.0791 - val_acc: 0.9800\n",
            "Epoch 143/150\n",
            "59/58 [==============================] - 53s 904ms/step - loss: 0.0870 - acc: 0.9725 - val_loss: 0.1600 - val_acc: 0.9560\n",
            "Epoch 144/150\n",
            "59/58 [==============================] - 53s 902ms/step - loss: 0.0854 - acc: 0.9724 - val_loss: 0.0713 - val_acc: 0.9824\n",
            "Epoch 145/150\n",
            "59/58 [==============================] - 54s 907ms/step - loss: 0.0728 - acc: 0.9778 - val_loss: 0.1229 - val_acc: 0.9704\n",
            "Epoch 146/150\n",
            "59/58 [==============================] - 53s 903ms/step - loss: 0.0761 - acc: 0.9732 - val_loss: 0.0561 - val_acc: 0.9848\n",
            "Epoch 147/150\n",
            "59/58 [==============================] - 53s 897ms/step - loss: 0.0646 - acc: 0.9802 - val_loss: 0.3182 - val_acc: 0.9144\n",
            "Epoch 148/150\n",
            "59/58 [==============================] - 53s 896ms/step - loss: 0.0712 - acc: 0.9770 - val_loss: 0.1705 - val_acc: 0.9496\n",
            "Epoch 149/150\n",
            "59/58 [==============================] - 53s 900ms/step - loss: 0.0680 - acc: 0.9756 - val_loss: 0.1020 - val_acc: 0.9712\n",
            "Epoch 150/150\n",
            "59/58 [==============================] - 53s 904ms/step - loss: 0.0711 - acc: 0.9778 - val_loss: 0.1197 - val_acc: 0.9680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m6DpfVHrH4sd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}